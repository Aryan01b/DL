{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tGk3jEiv131",
        "outputId": "0c58ba41-4696-4a8b-e03c-5f3b114519ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vectorAdd.cu\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void Add(int *a, int *b, int *c, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 2;\n",
        "    int *a, *b, *c;\n",
        "\n",
        "    // Allocate memory on host\n",
        "    a = (int *)malloc(n * sizeof(int));\n",
        "    b = (int *)malloc(n * sizeof(int));\n",
        "    c = (int *)malloc(n * sizeof(int));\n",
        "\n",
        "    // Initialize data on host\n",
        "    for (int i = 0; i < n; ++i) {\n",
        "      printf(\"Enter a[%d]: \", i);\n",
        "      scanf(\"%d\", &a[i]);\n",
        "      printf(\"Enter b[%d]: \", i);\n",
        "      scanf(\"%d\", &b[i]);\n",
        "    }\n",
        "\n",
        "    // Allocate memory on device (GPU)\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    cudaMalloc(&d_a, n * sizeof(int));\n",
        "    cudaMalloc(&d_b, n * sizeof(int));\n",
        "    cudaMalloc(&d_c, n * sizeof(int));\n",
        "\n",
        "    // Copy data from host to device\n",
        "    cudaMemcpy(d_a, a, n * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, n * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch the kernel on the GPU\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    Add<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);\n",
        "\n",
        "    // Copy results back from device to host\n",
        "    cudaMemcpy(c, d_c, n * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print the result\n",
        "    for (int i = 0; i < n; ++i) {\n",
        "        printf(\"%d + %d = %d\\n\", a[i], b[i], c[i]);\n",
        "    }\n",
        "\n",
        "    // Free memory\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSFanj-NxS5R",
        "outputId": "f29470ad-a8c5-4669-8282-e8e68216bfe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vectorAdd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!nvcc vectorAdd.cu -o vecAdd"
      ],
      "metadata": {
        "id": "lZO0hLjCu2Jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vecAdd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ifat6Byu8ew",
        "outputId": "74ce3ff8-07d9-407b-9b2e-5935f860e478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a[0]: 5\n",
            "Enter b[0]: 6\n",
            "Enter a[1]: 11\n",
            "Enter b[1]: 3\n",
            "5 + 6 = 11\n",
            "11 + 3 = 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Mat_Mul.cu\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define N 3\n",
        "\n",
        "__global__ void matrix_mul(int *a, int *b, int *c, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int j = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int sum = 0;\n",
        "    if (i < n && j < n) {\n",
        "        for (int k = 0; k < n; k++)\n",
        "            sum += a[i * n + k] * b[k * n + j];\n",
        "        c[i * n + j] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = N;\n",
        "    int *a, *b, *c;\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    int size = n * n * sizeof(int);\n",
        "\n",
        "    // Allocate memory for matrices A, B, and C on the host\n",
        "    a = (int *)malloc(size);\n",
        "    b = (int *)malloc(size);\n",
        "    c = (int *)malloc(size);\n",
        "\n",
        "    // Initialize matrices A and B with hard-coded values\n",
        "    int a_values[N][N] = {{1, 1, 1}, {1, 1, 1}, {1, 1, 1}};\n",
        "    int b_values[N][N] = {{1, 1, 1}, {1, 1, 1}, {1, 1, 1}};\n",
        "\n",
        "    // Copy values to matrices A and B\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            a[i * N + j] = a_values[i][j];\n",
        "            b[i * N + j] = b_values[i][j];\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Allocate memory for matrices A, B, and C on the device\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "    cudaMalloc((void **)&d_b, size);\n",
        "    cudaMalloc((void **)&d_c, size);\n",
        "\n",
        "    // Copy matrices A and B from host to device\n",
        "    cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define grid and block dimensions\n",
        "    dim3 blockSize(N, N);\n",
        "    dim3 gridSize((n + N - 1) / N, (n + N - 1) / N);\n",
        "\n",
        "    // Launch kernel\n",
        "    matrix_mul<<<gridSize, blockSize>>>(d_a, d_b, d_c, n);\n",
        "\n",
        "    // Copy result matrix C from device to host\n",
        "    cudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print the result matrix C\n",
        "    printf(\"Result matrix:\\n\");\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        for (int j = 0; j < n; j++)\n",
        "            printf(\"%d \", c[i * n + j]);\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    // Free host memory\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM9l2vayu-eX",
        "outputId": "e6e8c4cf-29d5-43d1-dba0-3dc85785ad88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Mat_Mul.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc Mat_Mul.cu -o mat_mul"
      ],
      "metadata": {
        "id": "sVPOxNu6xpj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./mat_mul"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAR5379lxvwC",
        "outputId": "ad9341ec-73cc-427c-e401-14f0ed54df69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result matrix:\n",
            "0 0 0 \n",
            "0 0 0 \n",
            "0 0 0 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile BFS.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "#define MAX_VERTICES 100\n",
        "\n",
        "__global__ void BFS(int *graph, int *visited, int *queue, int *front, int *rear, int V) {\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    while (*front < *rear) {\n",
        "        int u = atomicAdd(front, 1);\n",
        "\n",
        "        if (u < *rear) {\n",
        "            visited[u] = 1;\n",
        "\n",
        "            for (int v = 0; v < V; v++) {\n",
        "                if (graph[u * V + v] && !visited[v]) {\n",
        "                    int rear_local = atomicAdd(rear, 1);\n",
        "                    queue[rear_local] = v;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int V, E, i, j;\n",
        "\n",
        "    printf(\"Enter the number of vertices: \");\n",
        "    scanf(\"%d\", &V);\n",
        "\n",
        "    printf(\"Enter the number of edges: \");\n",
        "    scanf(\"%d\", &E);\n",
        "\n",
        "    int *graph = (int *)malloc(V * V * sizeof(int));\n",
        "    int *visited = (int *)calloc(V, sizeof(int));\n",
        "    int *queue = (int *)malloc(V * sizeof(int));\n",
        "    int front = 0, rear = 0;\n",
        "\n",
        "    int *d_graph, *d_visited, *d_queue, *d_front, *d_rear;\n",
        "    cudaMalloc(&d_graph, V * V * sizeof(int));\n",
        "    cudaMalloc(&d_visited, V * sizeof(int));\n",
        "    cudaMalloc(&d_queue, V * sizeof(int));\n",
        "    cudaMalloc(&d_front, sizeof(int));\n",
        "    cudaMalloc(&d_rear, sizeof(int));\n",
        "\n",
        "    printf(\"Enter the graph connections (source, destination) for %d edges:\\n\", E);\n",
        "    for (int e = 0; e < E; e++) {\n",
        "      scanf(\"%d %d\", &i, &j);\n",
        "      graph[i * V + j] = graph[j * V + i] = 1;\n",
        "    }\n",
        "\n",
        "\n",
        "    cudaMemcpy(d_graph, graph, V * V * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_visited, visited, V * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_front, &front, sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_rear, &rear, sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int start;\n",
        "    printf(\"Enter the starting vertex for BFS: \");\n",
        "    scanf(\"%d\", &start);\n",
        "\n",
        "    // Initialize visited array to zeros\n",
        "for (i = 0; i < V; i++) {\n",
        "    visited[i] = 0;\n",
        "}\n",
        "\n",
        "// Mark the start node as visited and enqueue it\n",
        "visited[start] = 1;\n",
        "queue[rear++] = start;\n",
        "\n",
        "// Copy the updated queue back to the device\n",
        "cudaMemcpy(d_queue, queue, V * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "// Launch the BFS kernel\n",
        "BFS<<<(V + 255) / 256, 256>>>(d_graph, d_visited, d_queue, d_front, d_rear, V);\n",
        "\n",
        "// Wait for kernel to finish\n",
        "cudaDeviceSynchronize();\n",
        "\n",
        "// Copy the visited array back to the host\n",
        "cudaMemcpy(visited, d_visited, V * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "// Print BFS traversal sequence\n",
        "printf(\"Breadth First Search Traversal: \");\n",
        "for (i = 0; i < V; i++) {\n",
        "    if (visited[i])\n",
        "        printf(\"%d \", i);\n",
        "}\n",
        "printf(\"\\n\");\n",
        "\n",
        "return 0;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3Terw-Upm55",
        "outputId": "2ea30373-d65b-4b6d-bb56-02035356d2fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting BFS.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc BFS.cu -o bfs"
      ],
      "metadata": {
        "id": "1KOqpyEMp4zT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./bfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-1G8yZWp7vI",
        "outputId": "588afee2-5c16-4d5f-d46b-a0140a03d552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BFS traversal: 0 0 0 0 0 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jMLzyLBMqAm-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}